{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fight-Online-Abuse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn import metrics\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from transformers import DistilBertModel, DistilBertTokenizerFast\n",
    "\n",
    "from datasets import TextDataset\n",
    "from models import DistilBertClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = Path('./datasets/jigsaw-toxic-comment-classification-challenge')\n",
    "RESULT_DIR = Path('./results')\n",
    "CHECKPOINT_DIR = Path('./checkpoints')\n",
    "RESULT_DIR.mkdir(exist_ok=True)\n",
    "CHECKPOINT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "TEXT_FIELD = 'comment_text'\n",
    "LABEL_FIELDS = ['toxic','severe_toxic','obscene','threat','insult', 'identity_hate']\n",
    "NUM_LABELS = len(LABEL_FIELDS)\n",
    "\n",
    "TRAIN_SPLIT = 0.8\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-05\n",
    "EPOCHS = 10\n",
    "PRED_THRES = 0.4   \n",
    "\n",
    "print(f\"Labels: {LABEL_FIELDS}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories: ['toxic' 'severe_toxic' 'obscene' 'threat' 'insult' 'identity_hate']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0000997932d777bf</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000103f0d9cfb60f</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000113f07ec002fd</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001b41b1c6bb37e</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001d958c54c6e35</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       comment_text  toxic  \\\n",
       "id                                                                           \n",
       "0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "id                                                                      \n",
       "0000997932d777bf             0        0       0       0              0  \n",
       "000103f0d9cfb60f             0        0       0       0              0  \n",
       "000113f07ec002fd             0        0       0       0              0  \n",
       "0001b41b1c6bb37e             0        0       0       0              0  \n",
       "0001d958c54c6e35             0        0       0       0              0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATASET_DIR / 'train.csv', index_col=0)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values present in training dataset: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\bs4\\__init__.py:417: MarkupResemblesLocatorWarning: \"http://en.wikipedia.org/wiki/Wikipedia_talk:No_original_research/archive15#YouTube_art_as_primary_source\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\bs4\\__init__.py:417: MarkupResemblesLocatorWarning: \"http://finance.yahoo.com/news/7-fascinating-nuggets-another-bewildering-150348488.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\bs4\\__init__.py:417: MarkupResemblesLocatorWarning: \"http://en.wikipedia.org/wiki/Wikipedia:ELYES\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\bs4\\__init__.py:417: MarkupResemblesLocatorWarning: \"http://www.haaretz.com/news/diplomacy-defense/2-279-calories-per-person-how-israel-made-sure-gaza-didn-t-starve.premium-1.470419\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning reduced text size by 1.2%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABEAAAAFwCAYAAAC4vQ5FAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAA2cUlEQVR4nO3deZxkVX3//9ebQRQXNkFEFoHAV2M07oKJkXEJoPgVTAyCqKgoyU/cjRETI7gGd0WNkSgCLiF8ccOAIqItGgOCYkBFZYRBQBZlWBxRcPTz++Oe1qKp7pma6a7uuf16Ph71uFXnnnvvqdt9HtX17nvOTVUhSZIkSZLUZxvMdwMkSZIkSZLmmgGIJEmSJEnqPQMQSZIkSZLUewYgkiRJkiSp9wxAJEmSJElS7xmASJIkSZKk3jMAkSRJApLsmKSSHLcA2nJca8uO83T8I9vxl04pryQT89GmgTbM67mRJK2/DEAkSQtCkiVJnp/kq0lWJPlNkmuTXJDkQ0mePN9tXOwGvhQfOd9tWVvj/AKfZHk73uTjN0muS3Jhko8m+ZskG83RsSeS1Fzse65NF75IkrSuNpzvBkiSlGQJ8F/A3sANwKnAFcBGwJ8ATwfuC5wyT02U1sV76H6vNwA2Ae4DPAV4BnBxkmdU1TenbPNq4CjgyjG2c9D7gBOBn8zT8Wcy3+dGkrSeMgCRJC0EB9KFH/8L7FFVNw6uTHJnYLf5aJg0C95dVcsHC5JsCrwBeBHwxSS7V9UPJtdX1VXAVWNt5YCq+jnw8/k6/kzm+9xIktZfDoGRJC0Ef9aWx00NPwCq6uaq+sqwDZMcmOQrSW5I8uskFyV5TZI7TlP/gCTfSvKrNsTmo0nuNWzIQJJnt0vxnz3NvoYOp0iyYZIXJDk7yU1Jbk5yfpIXJtlgSt3fzzvRnp+Y5OftvZyX5ElDz1i37dOSnNmGDP26Dbn4jyQPW9fzNBuSbJfkfUkuSXJLG/5xSpKHD6n7+2EPSZ6a5JvtvK1o52TbaY7x8CRfTPKLdq6/lOSRU4dRTP4s22Z7TBmacuSQ/Y70sxhVVd1YVS8GTgA2pbuiYfD4Q+e5SPLk9jO/qp3Tn6YbNvaCgXYXsEd7Pfg+Jwb2s7w9Nknyzvb8N5PnYnXDUFqf+WjrQ79qferpQ+qN1IeSLAeOaC+/Mtj+1Z2btm7/JGclubG168Ikrx72ez5wDu6S5G1JftLO6bIkr0qSYW2WJK2/vAJEkrQQXNeW/2eUjZIcCzyHbrjMJ+mGGexO95/1xyX5y6paNVD/ZcA7W70T2nIv4BvA7YKXtZHkDsDn2n5/CHwC+DXwGOC9dFeyPHPIpvcGvglcAnwU2AJ4GvDZJI8fDIDaF7OPAAfT/Zf+U8DPgO3acX4InDdQf6TzNBuSPAT4Ynsfp7c2bgnsB3w9yVOq6rQhm74AeDLdcKev0p2vpwEPTPKgqrpl4BiPbsdY0vb/Y+ABwFeAL0/Z73eA19F9ub4MOG5g3cSUumv8s5gFrweeBTwpySZVddN0FZMcCnwQuJrud+znwD2AP6X7+f4r3c/2dcCz2/t43cAulk/Z5UZ052kLuvN4E3DpGrR5c7o+cwPd7+FmwP7Ax5NsW1VvW4N9TOfddL8jewDHD2nztJK8mW54zM/p+t1K4AnAm4G9kuxZVbdO2ewOdL+f9wI+D6xqxz8KuBO3PX+SpPVdVfnw4cOHDx/z+gAeDNwK/I7uC+dfAfdezTbPBorui+/GU9Yd2da9ZKBsx3aMFcCOA+Ub0IUC1X0sDj3Gs6dpQwET0xz7vcCSgfIlwIfbun2ntKva44gp+9qrlZ82pfzQVv5NYNMp65YA26zteVrNOZ+sf+Rq6m0ILKMLfvaYsu5edHM3XAXccci+bwIeMGWbT7R1+0/5uV3cyp8wpf7fDZzTpav7ma3Lz2I152F522bH1dS7vNV7zEDZcVO3Bb4F3ALcY8g+tpzyemLq7/M0bfsScJcZftbDzl8BJwEbDJTvRNe3bgV2nqU+tHSabYadm0e2sp8A95zyu/i5tu4fpzkHpzHQN+hCpRva4w5r+vP24cOHDx8L/+EQGEnSvKuq8+kmhLymLT8JLG9DJj6d5P8O2ewldP+tfW5V/WrKujfQXVVy0EDZQXT/7X1vDczHUFW/A15JF76sk3TDW15E9x/6l1XVbweO81vgFXRfuA4asvllwBsHC6rqdLovdI+YUvdFbfm3NWXIUFX9tro5EiaNep5mwz7AH9Gd669Oad9PgbcC9wQeN2Tbo6vqwill/96Wg+fhz4BdgK9U1een1D8G+NFath1G+1nMhsnJPLdag7qrgN9MLaxuzo618Yqq+uWI2/wWeFXrO5PHvxQ4mq6PDbvCaa49ty3fWFVXD7RrFV2/+x3wvGm2ffFg36iqa4HP0g1Nus/cNFeSNB8cAiNJWhCq6qQkn6YbwvEouqtCHkV3Ofp+SU6g+y9ypZsU9YF0l7q/dJqh+rcAfzzw+iFt+dWpFavqkiSX0w0ZWBf/h244wcXAa6Zp16+mtGvSdwYDkwGX0/13G4AkdwHuD1zTgqNpreV5mg2T7b33sPk1gF3b8o/p/vs+6Dxu7/K23Hyg7MFt+fWplavqd0m+wYhDqgas0c9iFk3+YFZ329qPA+8Avp/kRLrf5f+uqp+t5XF/DVywFtv9pAUeU03QDTF68JB1c22yf08d+kRV/SjJFcBOSTadEhreWFXLhuxv2O+cJGk9ZwAiSVowquo3dHMRfBF+f3vcvwaOpZsn4dPAZ+i+lITuP+ZHDNvXEJu25TXTrL+adQ9A7t6WuzJzu+46pOyGaequ4raTlm/WlmtyC9C1OU+zYfI8/M1q6q3peZicn2TJQNnqfp7Tla+JYW2YbMdcXD17r7acMcioqncm+TndPCkvBl4KVJKvAq+sqmHh0UyurarVhS7DzNSH4A8/m3GaPOZ0d4e5CtiBrv8MBiA3TFN/2O+cJGk95xAYSdKC1YZznAS8qxU9ti0nv8CcX1WZ6TGwu8lttp7mcPccUjZ5if/t/mGQZLMh9SeP8enVtGunadqwJm5oy6F3RZmmPaOcp9kwedx9V3PcdZlgcnKy0Ol+ntOVLyhJdqGbvHYV3RwfM6qqE6pqd7qQaR+6eWUeDZyeZE2G0NxmdyPWn7S6PjQYMIzah9bW5DGH9WOAbabUkyQtQgYgkqT1wS/aMgBVtRL4HvAnSbZYw318uy33mLoiyc7A9kO2ub4th6273a1mgR/Q7rDS7gYz69p8Dd8Ftk4y41CDtTxPs+HstvyLOTzG5PCfR01d0eZi+bOp5c3vWFj/1X9tW36uqn4xY80BVXVDVZ1WVc+nmxR0C7ogZNJv4fdXUc22HYbdghZY2paDQ7NG7UPQ2s5oP6fJYy6dumIgZLq0qm4YYZ+SpJ4xAJEkzbskByb5y/bFdeq6ewLPby/PGlj1TrrbeB477D/JSTZvt2Kd9HG6ySNfNPjlrR3zbQz/TDyP7gvz09t8GpPbbEE3kedttAkX30v33+ajk2w8pF3bJLnfkGON4ui2/GCS2ww3SLJBkm0GikY9T7Phs3S3pD0syROHVUjyyMFzuhb+ux3jMUmeMGXdoUw//8d1DP8yPlZJNklyNN2EoTcAh6/BNo/J8Ilc7tGWNw+UTd5aeod1aec0lgBvGeyvSXaiG5azCvjYQN2R+lCzNm0/ti1fM3glTAuA3k7Xvz88wv4kST3kHCCSpIVgN7q7lVyd5OvA5ASLO9Fd5r8x3Zfqkyc3qKpjkzyUbj6EHyeZvEvHFm27RwMfobslKlW1PMnhdJNInp/kP+kuh9+Lbl6AC4A/HWxUVV2V5ON0X1K/k+RUYBPgiXRhzLArMN5AN/Ho3wH/N8mX6ebruAfd3CB/DvwT8P21OVHNh+iurngmcHGSz9LNH3EvumFCx9LdSnTk87SG9pvmCgCAL1bVJ5L8FXA6cGqbkPQ7dF/QtwceDuxMFxTdPM1+ZtQmOn0e8AXglCSfpAtE/hT4S+DzwBO4/d19zgQOSPI5uquCfgOcVVVnMXdemuQGuiuYNqG7s8ijgbvQ3a3mGVW1Jnet+TSwMsnZdLdwDd3vwcPphs98aaDumXRzsHwqyWl0k+9eVlUfnYX3cwFdn/1Wki/S9Z/92/IfqurHkxXXsg99he7n9i9J7k+7iqSq3jik7uRxvpHkrcA/AN9NcjLwS7rfgfvTTZb7tnV4z5KkHjAAkSQtBO+gu3PK4+m+wO4F3InuP8ETwCeAT0ydsLGqDkvyebov74+n+wK2gu4L/tu47X+iJyeRvIrutrfPphtaczrdl6ZPTNO259NN+nggcFjb99Ft//tPrVxVv0myH93tfJ8NPIluss+f0QU7/0x3Ncpaa+fhWS3MOLS14450Ez1+DThlSv2RztMaeGB7DHMD3c/qgiQPBF5Odw6eQ/el9iq64QpH0N2dZq1V1USSPehuWbtPKz6H7k5Ck7f2vWnKZi+hm/vicXRfwjcAXsdtry6abS9py1V0v3NX0oUZnwVOqapb13A/h9P1jYfQtf3XdLfsfRXwgTaJ8KQP0U3qewDd7/eGdHeNmY0A5Hq6YOGtdD/XTegCvbdX1bB+NGofuijJwcDf0wV3d2qrpg1A2navSnI+8EK6SZPvQBeKvQZ4xwjnWZLUU1m7yb8lSeqXJBPAHnMwIajmQZL/prtKYdM2b4okSVrknANEkiStl5LceZp5TZ5NNwnqFw0/JEnSJIfASJKk9dUOdPO5nAEso/u75sF0d4a5AXjF/DVNkiQtNAYgkiRpfXUN3Xwqe9DN+3FH4Gq6SV3fNDgZpyRJknOASJIkSZKk3nMOEEmSJEmS1HsOgQE222yz2mWXXea7GdKC9Mtf/pK73OUu890MacGyj0gzs49IM7OPSDP71re+9fOq2mo29mUAAmy99dacd955890MaUGamJhg6dKl890MacGyj0gzs49IM7OPSDNLctls7cshMJIkSZIkqfcMQCRJkiRJUu8ZgEiSJEmSpN4zAJEkSZIkSb1nACJJkiRJknrPAESSJEmSJPWeAYgkSZIkSeo9AxBJkiRJktR7BiCSJEmSJKn3DEAkSZIkSVLvGYBIkiRJkqTeMwCRJEmSJEm9t+F8N2Ah+NVvfsuOh586tuMtP2qfsR1LkiRJkiR5BYgkSZIkSVoEDEAkSZIkSVLvGYBIkiRJkqTeMwCRJEmSJEm9ZwAiSZIkSZJ6zwBEkiRJkiT1ngGIJEmSJEnqPQMQSZIkSZLUewYgkiRJkiSp9wxAJEmSJElS7xmASJIkSZKk3jMAkSRJkiRJvWcAIkmSJEmSes8ARJIkSZIk9Z4BiCRJkiRJ6j0DEEmSJEmS1HsGIJIkSZIkqfcMQCRJkiRJUu8ZgEiSJEmSpN4zAJEkSZIkSb1nACJJkiRJknrPAESSJEmSJPWeAYgkSZIkSeq9sQcgSTZLcnKSHyS5KMkjk2yR5IwkF7fl5q1ukhydZFmSC5I8ZGA/B7f6Fyc5eKD8oUkubNscnSTjfo+SJEmSJGlhmY8rQN4DfKGq7gs8ELgIOBw4s6p2Bc5srwGeAOzaHocCHwBIsgVwBLAb8AjgiMnQpNV5/sB2e4/hPUmSJEmSpAVsrAFIkk2BRwMfBqiqW6vqBmBf4PhW7Xhgv/Z8X+CE6pwNbJZkG2Av4IyqWlFV1wNnAHu3dZtU1dlVVcAJA/uSJEmSJEmL1LivANkJ+BnwkSTnJ/lQkrsAW1fVVa3O1cDW7fm2wOUD21/RymYqv2JIuSRJkiRJWsQ2nIfjPQR4UVWdk+Q9/GG4CwBVVUlqrhuS5FC6YTVsueVWvPYBq+b6kL83MTExtmNJ62rlypX+zkozsI9IM7OPSDOzj0jjM+4A5Argiqo6p70+mS4AuSbJNlV1VRvGcm1bfyWw/cD227WyK4GlU8onWvl2Q+rfTlUdAxwDsMPOu9Q7LhzfqVh+0NKxHUtaVxMTEyxdunS+myEtWPYRaWb2EWlm9hFpfMY6BKaqrgYuT3KfVvQ44PvAKcDknVwOBj7bnp8CPKvdDWZ34MY2VOZ0YM8km7fJT/cETm/rbkqye7v7y7MG9iVJkiRJkhapcV8BAvAi4ONJNgIuAZ5DF8SclOQQ4DJg/1b3NOCJwDLg5laXqlqR5A3Aua3e66tqRXv+AuA4YGPg8+0hSZIkSZIWsbEHIFX1HeBhQ1Y9bkjdAg6bZj/HAscOKT8PuP+6tVKSJEmSJPXJuO8CI0mSJEmSNHYGIJIkSZIkqfcMQCRJkiRJUu8ZgEiSJEmSpN4zAJEkSZIkSb1nACJJkiRJknrPAESSJEmSJPWeAYgkSZIkSeo9AxBJkiRJktR7BiCSJEmSJKn3DEAkSZIkSVLvGYBIkiRJkqTeMwCRJEmSJEm9ZwAiSZIkSZJ6zwBEkiRJkiT1ngGIJEmSJEnqPQMQSZIkSZLUewYgkiRJkiSp9wxAJEmSJElS7xmASJIkSZKk3jMAkSRJkiRJvWcAIkmSJEmSes8ARJIkSZIk9Z4BiCRJkiRJ6j0DEEmSJEmS1HsGIJIkSZIkqfcMQCRJkiRJUu8ZgEiSJEmSpN4zAJEkSZIkSb1nACJJkiRJknrPAESSJEmSJPWeAYgkSZIkSeo9AxBJkiRJktR7BiCSJEmSJKn3xh6AJFme5MIk30lyXivbIskZSS5uy81beZIcnWRZkguSPGRgPwe3+hcnOXig/KFt/8vathn3e5QkSZIkSQvLfF0B8piqelBVPay9Phw4s6p2Bc5srwGeAOzaHocCH4AuMAGOAHYDHgEcMRmatDrPH9hu77l/O5IkSZIkaSFbKENg9gWOb8+PB/YbKD+hOmcDmyXZBtgLOKOqVlTV9cAZwN5t3SZVdXZVFXDCwL4kSZIkSdIiteE8HLOALyYp4INVdQywdVVd1dZfDWzdnm8LXD6w7RWtbKbyK4aU306SQ+muKmHLLbfitQ9YtS7vaSQTExNjO5a0rlauXOnvrDQD+4g0M/uINDP7iDQ+8xGAPKqqrkxyD+CMJD8YXFlV1cKROdWCl2MAdth5l3rHheM7FcsPWjq2Y0nramJigqVLl853M6QFyz4izcw+Is3MPiKNz9iHwFTVlW15LfBpujk8rmnDV2jLa1v1K4HtBzbfrpXNVL7dkHJJkiRJkrSIjTUASXKXJHebfA7sCXwXOAWYvJPLwcBn2/NTgGe1u8HsDtzYhsqcDuyZZPM2+emewOlt3U1Jdm93f3nWwL4kSZIkSdIiNe4hMFsDn253pt0Q+ERVfSHJucBJSQ4BLgP2b/VPA54ILANuBp4DUFUrkrwBOLfVe31VrWjPXwAcB2wMfL49JEmSJEnSIjbWAKSqLgEeOKT8OuBxQ8oLOGyafR0LHDuk/Dzg/uvcWEmSJEmS1BsL5Ta4kiRJkiRJc8YARJIkSZIk9Z4BiCRJkiRJ6j0DEEmSJEmS1HsGIJIkSZIkqfcMQCRJkiRJUu8ZgEiSJEmSpN4zAJEkSZIkSb1nACJJkiRJknrPAESSJEmSJPWeAYgkSZIkSeo9AxBJkiRJktR7BiCSJEmSJKn3DEAkSZIkSVLvGYBIkiRJkqTeMwCRJEmSJEm9ZwAiSZIkSZJ6zwBEkiRJkiT1ngGIJEmSJEnqPQMQSZIkSZLUeyMFIEnenGSHuWqMJEmSJEnSXBj1CpAXAZckOS3Jk5N4BYkkSZIkSVrwRg0wtgEOA7YGPgNcluSIJNvOdsMkSZIkSZJmy0gBSFWtrKoPVtVDgd2ALwKvBC5N8ukke89FIyVJkiRJktbFWg9hqapzq+oQYCfgG8C+wKlJLklymMNjJEmSJEnSQrHWIUWSP0ryVuB7wJ8DnwYOAv4HeDfwb7PRQEmSJEmSpHW14SiVkywBngL8LfAY4BrgA8AHq+qnrdqJSb4GvAU4dBbbKkmSJEmStFZGCkCAK4GtgLOAA4FPV9WqIfXOB+62jm2TJEmSJEmaFaMGICcBH6iqi2aqVFXnsA7DayRJkiRJkmbTSAFIVb14rhoiSZIkSZI0V0a6SiPJq5K8d5p1Ryd55ew0S5IkSZIkafaMOkzlOcAF06z7TlsvSZIkSZK0oIwagOwAXDzNukuAe69bcyRJkiRJkmbfqAHIzcC206zbDrhlTXaSZEmS85P8V3u9U5JzkixL8p9JNmrld2yvl7X1Ow7s49Wt/IdJ9hoo37uVLUty+IjvT5IkSZIk9dCoAcjXgFcmueNgYXv9irZ+TbwEGLyTzFuAd1XVLsD1wCGt/BDg+lb+rlaPJPcDDgD+BNgb+NcWqiwB3g88AbgfcGCrK0mSJEmSFrFRA5AjgV2BHyV5U5IXJHkT8KNW/trV7SDJdsA+wIfa6wCPBU5uVY4H9mvP922vaesf1+rvC5xYVbdU1aXAMuAR7bGsqi6pqluBE1tdSZIkSZK0iI16G9z/TfIY4O3Aq+gClN8BXwf+uqr+dw12827gH4C7tdd3B26oqlXt9RX8YZjNtsDl7dirktzY6m8LnD2wz8FtLp9Svtuavj9JkiRJktRPIwUgAFX1TeDRSTYGNqcbovKrNdk2yZOAa6vqW0mWjnrs2ZTkUOBQgC233IrXPmDVaraYPRMTE2M7lrSuVq5c6e+sNAP7iDQz+4g0M/uIND4jByCTWuixRsHHgD8HnpzkicCdgE2A9wCbJdmwXQWyHXBlq38lsD1wRZINgU2B6wbKJw1uM1351PYfAxwDsMPOu9Q7LlzrUzGy5QctHduxpHU1MTHB0qVL57sZ0oJlH5FmZh+RZmYfkcZn5G/9SXYG9qe7Je6dpqyuqjrk9lv9fuWrgVe3/SwF/r6qDkry/4Cn0s3ZcTDw2bbJKe31/7T1X66qSnIK8Ikk7wTuRTf/yDeBALsm2Yku+DgAePqo71GSJEmSJPXLSAFIkv2Ak+jm/riW29/2ttayHa8CTkzyRuB84MOt/MPAR5MsA1bQBRpU1feSnAR8H1gFHFZVv21tfCFwOrAEOLaqvreWbZIkSZIkST0x6hUgbwAmgIOq6mfrcuCqmmj7oqouobuDy9Q6vwb+Zprt3wS8aUj5acBp69I2SZIkSZLUL6MGIDsDr1jX8EOSJEmSJGmcNhix/g/obkMrSZIkSZK03hj1CpB/AN6d5Jw2bEVrYcfDTx3r8ZYftc9YjydJkiRJ0kIzagByJN0VIBcluZhuYtJBVVV7zEbDJEmSJEmSZsuoAchvgR/ORUMkSZIkSZLmykgBSFUtnaN2SJIkSZIkzZlRJ0GVJEmSJEla74wcgCTZNsk7k5yX5NIk92/lL02y2+w3UZIkSZIkad2MFIAk+RPgQuCZwE+BHYCN2up7Ay+Z1dZJkiRJkiTNglGvAHkHcBGwE/BXQAbWfQPYfZbaJUmSJEmSNGtGvQvMo4ADq2plkiVT1l0D3HN2miVJkiRJkjR7Rr0C5HczrNsS+NU6tEWSJEmSJGlOjBqAfBN4zjTr9gf+e92aI0mSJEmSNPtGHQLzBuBLSb4IfAIo4PFJXgI8BXj0LLdPkiRJkiRpnY10BUhVfRXYj24S1GPpJkE9CvgLYL+qOme2GyhJkiRJkrSuRr0ChKo6FTg1yS7APYDrquqHs94ySZIkSZKkWTJyADKpqpYBy2axLZIkSZIkSXNipAAkybNWV6eqTlj75kiSJEmSJM2+Ua8AOW6a8hp4bgAiSZIkSZIWlFEDkJ2GlN0deBLwdOAZ69wiSZIkSZKkWTZSAFJVlw0pvgz4dpIAL6cLQiRJkiRJkhaMkW6DuxpfA/aZxf1JkiRJkiTNitkMQHYHVs7i/iRJkiRJkmbFqHeBee2Q4o2A+9Nd/fG+2WiUJEmSJEnSbBp1EtQjh5TdQjcPyJuAf1nXBkmSJEmSJM22USdBnc0hM5IkSZIkSWNhoCFJkiRJknpv1DlAdhilflX9ZLTmSJIkSZIkzb5R5wBZDtQI9ZeMuH9JkiRJkqRZN2oA8v8B/wTcBJwEXAPcE9gfuCvdRKi3zGYDJUmSJEmS1tWoAcgfA98GnlJVv78SJMnrgc8Af1xVL5u95kmSJEmSJK27USdBPRD44GD4AdBe/xvw9NlqmCRJkiRJ0mwZNQC5K7DVNOvuAdxl3ZojSZIkSZI0+0YNQCaANyd5+GBhkkfQzf8xMTvNkiRJkiRJmj2jBiAvpJvk9Owky5Ock2Q58D/Ar9v6aSW5U5JvJvnfJN9L8rpWvlPb17Ik/5lko1Z+x/Z6WVu/48C+Xt3Kf5hkr4HyvVvZsiSHj/j+JEmSJElSD40UgFTVpcB9gb8DzgSua8u/pZsAdflqdnEL8NiqeiDwIGDvJLsDbwHeVVW7ANcDh7T6hwDXt/J3tXokuR9wAPAnwN7AvyZZkmQJ8H7gCcD9gANbXUmSJEmStIiNehcYquo3wL+3x6jbFrCyvbxDexTwWP4wgerxwJHAB4B923OAk4H3JUkrP7GqbgEuTbIMeESrt6yqLgFIcmKr+/1R2ypJkiRJkvpj5AAEIMmfAo8G7k53V5irk+wCXFNVv1jNtkuAbwG70F2t8WPghqpa1apcAWzbnm8LXA5QVauS3NiOuS1w9sBuB7e5fEr5btO041DgUIAtt9yK1z5g1bBqvTAxMTHfTdB6bOXKlf4OSTOwj0gzs49IM7OPSOMzUgCS5I7Ax4C/AkJ39cbngKuBtwI/Amacd6Oqfgs8KMlmwKfphtSMXVUdAxwDsMPOu9Q7LlyrLGi9sPygpfPdBK3HJiYmWLp06Xw3Q1qw7CPSzOwj0szsI9L4jDoJ6puAxwPPBLamC0EmfR7Ya9hGw1TVDcBXgEcCmyWZTCC2A65sz68Etgdo6zelm3fk9+VTtpmuXJIkSZIkLWKjBiAHAq+pqk8AK6asuxTYcaaNk2zVrvwgycbAXwIX0QUhT23VDgY+256f0l7T1n+5zSNyCnBAu0vMTsCuwDeBc4Fd211lNqKbKPWUEd+jJEmSJEnqmVHHfdydLrAYZgPgjqvZfhvg+DYPyAbASVX1X0m+D5yY5I3A+cCHW/0PAx9tk5yuoAs0qKrvJTmJbnLTVcBhbWgNSV4InA4sAY6tqu+N+B4lSZIkSVLPjBqAXEo3ZOXLQ9Y9AvjhTBtX1QXAg4eUX8If7uIyWP5r4G+m2deb6IbkTC0/DThtpnZIkiRJkqTFZdQhMCcAhyc5iO4WtgCV5DHAy4BjZ7NxkiRJkiRJs2HUAOStwKnAR4HrW9nXgS8BX6iq985i2yRJkiRJkmbFSENg2jwbByR5P90dX+5Bd1eWL1TVV+egfZIkSZIkSetsjQOQdleVs4HDq+qLwNfmrFWSJEmSJEmzaI2HwFTVrcBOdHddkSRJkiRJWm+MOgfIGcCec9EQSZIkSZKkuTLqbXDfC3wsyYbAZ4CrgBqs0G5pK0mSJEmStGCMGoBMTnT6crrb3g6zZO2bI0mSJEmSNPtWG4AkeSzwzapaCTyXKVd8SJIkSZIkLXRrcgXIGcAj6UKQ45JsAEwAh1TVxXPZOEmSJEmSpNmwJpOgZsjrRwF3m/3mSJIkSZIkzb5R7wIjSZIkSZK03jEAkSRJkiRJvbemd4HZNsnO7fmSgbIbplb0NriSJEmSJGmhWdMA5OQhZZ+Zpq63wZUkSZIkSQvKmgQgz5nzVkiSJEmSJM2h1QYgVXX8OBoiSZIkSZI0V5wEVZIkSZIk9Z4BiCRJkiRJ6j0DEEmSJEmS1HsGIJIkSZIkqfcMQCRJkiRJUu8ZgEiSJEmSpN4zAJEkSZIkSb1nACJJkiRJknrPAESSJEmSJPWeAYgkSZIkSeo9AxBJkiRJktR7BiCSJEmSJKn3DEAkSZIkSVLvGYBIkiRJkqTeMwCRJEmSJEm9ZwAiSZIkSZJ6b6wBSJLtk3wlyfeTfC/JS1r5FknOSHJxW27eypPk6CTLklyQ5CED+zq41b84ycED5Q9NcmHb5ugkGed7lCRJkiRJC8+4rwBZBbyiqu4H7A4cluR+wOHAmVW1K3Bmew3wBGDX9jgU+AB0gQlwBLAb8AjgiMnQpNV5/sB2e4/hfUmSJEmSpAVsrAFIVV1VVd9uz38BXARsC+wLHN+qHQ/s157vC5xQnbOBzZJsA+wFnFFVK6rqeuAMYO+2bpOqOruqCjhhYF+SJEmSJGmRmrc5QJLsCDwYOAfYuqquaquuBrZuz7cFLh/Y7IpWNlP5FUPKJUmSJEnSIrbhfBw0yV2BTwIvraqbBqfpqKpKUmNow6F0w2rYcsuteO0DVs31IefNxMTEfDdB67GVK1f6OyTNwD4izcw+Is3MPiKNz9gDkCR3oAs/Pl5Vn2rF1yTZpqquasNYrm3lVwLbD2y+XSu7Elg6pXyilW83pP7tVNUxwDEAO+y8S73jwnnJgsZi+UFL57sJWo9NTEywdOnS+W6GtGDZR6SZ2UekmdlHpPEZ67f+dkeWDwMXVdU7B1adAhwMHNWWnx0of2GSE+kmPL2xhSSnA28emPh0T+DVVbUiyU1JdqcbWvMs4L1z/sYWuB0PP3Wsx1t+1D5jPZ4kSZIkSasz7sse/hx4JnBhku+0sn+kCz5OSnIIcBmwf1t3GvBEYBlwM/AcgBZ0vAE4t9V7fVWtaM9fABwHbAx8vj0kSZIkSdIiNtYApKq+DmSa1Y8bUr+Aw6bZ17HAsUPKzwPuvw7NlCRJkiRJPTNvd4GRJEmSJEkaFwMQSZIkSZLUewYgkiRJkiSp9wxAJEmSJElS7xmASJIkSZKk3jMAkSRJkiRJvWcAIkmSJEmSes8ARJIkSZIk9Z4BiCRJkiRJ6j0DEEmSJEmS1HsGIJIkSZIkqfcMQCRJkiRJUu8ZgEiSJEmSpN4zAJEkSZIkSb1nACJJkiRJknrPAESSJEmSJPWeAYgkSZIkSeo9AxBJkiRJktR7BiCSJEmSJKn3DEAkSZIkSVLvGYBIkiRJkqTeMwCRJEmSJEm9ZwAiSZIkSZJ6zwBEkiRJkiT1ngGIJEmSJEnqPQMQSZIkSZLUewYgkiRJkiSp9wxAJEmSJElS7xmASJIkSZKk3jMAkSRJkiRJvWcAIkmSJEmSes8ARJIkSZIk9Z4BiCRJkiRJ6j0DEEmSJEmS1HtjDUCSHJvk2iTfHSjbIskZSS5uy81beZIcnWRZkguSPGRgm4Nb/YuTHDxQ/tAkF7Ztjk6Scb4/SZIkSZK0MG045uMdB7wPOGGg7HDgzKo6Ksnh7fWrgCcAu7bHbsAHgN2SbAEcATwMKOBbSU6pqutbnecD5wCnAXsDnx/D+9KAHQ8/dazHW37UPmM9niRJkiRp/TPWK0Cq6ixgxZTifYHj2/Pjgf0Gyk+oztnAZkm2AfYCzqiqFS30OAPYu63bpKrOrqqiC1n2Q5IkSZIkLXrjvgJkmK2r6qr2/Gpg6/Z8W+DygXpXtLKZyq8YUj5UkkOBQwG23HIrXvuAVevwFjSfJiYm5rsJvbZy5UrPsTQD+4g0M/uINDP7iDQ+CyEA+b2qqiQ1pmMdAxwDsMPOu9Q7LlxQp0IjWH7Q0vluQq9NTEywdOnS+W6GtGDZR6SZ2UekmdlHpPFZCHeBuaYNX6Etr23lVwLbD9TbrpXNVL7dkHJJkiRJkrTILYQA5BRg8k4uBwOfHSh/VrsbzO7AjW2ozOnAnkk2b3eM2RM4va27Kcnu7e4vzxrYlyRJkiRJWsTGOu4jyX8AS4Etk1xBdzeXo4CTkhwCXAbs36qfBjwRWAbcDDwHoKpWJHkDcG6r9/qqmpxY9QV0d5rZmO7uL94BRpIkSZIkjTcAqaoDp1n1uCF1Czhsmv0cCxw7pPw84P7r0kZJkiRJktQ/C2EIjCRJkiRJ0pwyAJEkSZIkSb1nACJJkiRJknrPAESSJEmSJPWeAYgkSZIkSeo9AxBJkiRJktR7BiCSJEmSJKn3DEAkSZIkSVLvGYBIkiRJkqTe23C+GyCtqx0PP3Wsx1t+1D5jPZ4kSZIkad15BYgkSZIkSeo9AxBJkiRJktR7BiCSJEmSJKn3DEAkSZIkSVLvGYBIkiRJkqTeMwCRJEmSJEm9ZwAiSZIkSZJ6zwBEkiRJkiT13obz3QBpfbPj4aeO/ZjLj9pn7MeUJEmSpD7xChBJkiRJktR7BiCSJEmSJKn3DEAkSZIkSVLvGYBIkiRJkqTecxJUaT0w7olXnXRVkiRJUt94BYgkSZIkSeo9AxBJkiRJktR7BiCSJEmSJKn3nANE0u0Mzjnyiges4tlzPAeJc45IkiRJmmteASJJkiRJknrPAESSJEmSJPWeQ2AkzTtv8ytJkiRprhmASFp0DFwkSZKkxcchMJIkSZIkqfd6eQVIkr2B9wBLgA9V1VHz3CRJi5hXnEiSJEnzr3cBSJIlwPuBvwSuAM5NckpVfX9+WyZJ4zHuwAUMXSRJkrTw9S4AAR4BLKuqSwCSnAjsCxiASNIcmY/QZaF4xQNW8exZfv8GSpIkSbOvjwHItsDlA6+vAHabp7ZIkjSyxRwoqX/mIiSU+sQ+Mpz/DNBcSFXNdxtmVZKnAntX1fPa62cCu1XVC6fUOxQ4tL28P/DdsTZUWn9sCfx8vhshLWD2EWlm9hFpZvYRaWb3qaq7zcaO+ngFyJXA9gOvt2tlt1FVxwDHACQ5r6oeNp7mSesX+4c0M/uINDP7iDQz+4g0syTnzda++ngb3HOBXZPslGQj4ADglHlukyRJkiRJmke9uwKkqlYleSFwOt1tcI+tqu/Nc7MkSZIkSdI86l0AAlBVpwGnjbDJMXPVFqkH7B/SzOwj0szsI9LM7CPSzGatj/RuElRJkiRJkqSp+jgHiCRJkiRJ0m0s6gAkyd5JfphkWZLD57s90nxIsn2SryT5fpLvJXlJK98iyRlJLm7LzVt5khzd+s0FSR4yv+9AmntJliQ5P8l/tdc7JTmn9YP/bJNuk+SO7fWytn7HeW24NAZJNktycpIfJLkoySP9DJH+IMnL2t9Y303yH0nu5OeIFrMkxya5Nsl3B8pG/txIcnCrf3GSg9fk2Is2AEmyBHg/8ATgfsCBSe43v62S5sUq4BVVdT9gd+Cw1hcOB86sql2BM9tr6PrMru1xKPCB8TdZGruXABcNvH4L8K6q2gW4HjiklR8CXN/K39XqSX33HuALVXVf4IF0fcXPEAlIsi3wYuBhVXV/ups0HICfI1rcjgP2nlI20udGki2AI4DdgEcAR0yGJjNZtAEI3UlaVlWXVNWtwInAvvPcJmnsquqqqvp2e/4Luj9ct6XrD8e3ascD+7Xn+wInVOdsYLMk24y31dL4JNkO2Af4UHsd4LHAya3K1P4x2W9OBh7X6ku9lGRT4NHAhwGq6taqugE/Q6RBGwIbJ9kQuDNwFX6OaBGrqrOAFVOKR/3c2As4o6pWVNX1wBncPlS5ncUcgGwLXD7w+opWJi1a7TLLBwPnAFtX1VVt1dXA1u25fUeLzbuBfwB+117fHbihqla114N94Pf9o62/sdWX+mon4GfAR9owsQ8luQt+hkgAVNWVwNuBn9AFHzcC38LPEWmqUT831urzZDEHIJIGJLkr8EngpVV10+C66m4X5S2jtOgkeRJwbVV9a77bIi1QGwIPAT5QVQ8GfskfLlsG/AzR4tYuyd+XLiy8F3AX1uC/1NJiNpefG4s5ALkS2H7g9XatTFp0ktyBLvz4eFV9qhVfM3lZclte28rtO1pM/hx4cpLldEMlH0s338Fm7VJmuG0f+H3/aOs3Ba4bZ4OlMbsCuKKqzmmvT6YLRPwMkTqPBy6tqp9V1W+AT9F9tvg5It3WqJ8ba/V5spgDkHOBXdsMzBvRTUZ0yjy3SRq7Nq70w8BFVfXOgVWnAJOzKR8MfHag/FltRubdgRsHLleTeqWqXl1V21XVjnSfE1+uqoOArwBPbdWm9o/JfvPUVt//fKu3qupq4PIk92lFjwO+j58h0qSfALsnuXP7m2uyj/g5It3WqJ8bpwN7Jtm8XWm1ZyubURZzf0ryRLqx3UuAY6vqTfPbImn8kjwK+BpwIX+Y4+Af6eYBOQnYAbgM2L+qVrQP7/fRXb55M/Ccqjpv7A2XxizJUuDvq+pJSXamuyJkC+B84BlVdUuSOwEfpZtLZwVwQFVdMk9NlsYiyYPoJgneCLgEeA7dP9n8DJGAJK8DnkZ3573zgefRzVXg54gWpST/ASwFtgSuobuby2cY8XMjyXPpvrcAvKmqPrLaYy/mAESSJEmSJC0Oi3kIjCRJkiRJWiQMQCRJkiRJUu8ZgEiSJEmSpN4zAJEkSZIkSb1nACJJkiRJknrPAESSpPVckv2SnJXk2iS/SnJZks8k2Xu+27Y+SlJJ3jjf7ZgqyY5Jjmy3YZ66bnmSj81HuyRJWl8YgEiStB5L8mLg08DFwCHAPsDkl/fHzle7NCd2BI4AbheASJKk1dtwvhsgSZLWyd8Dn6mqQwbKvgz8exL/0SFJktT4h5EkSeu3LYCrh62oqt8Nvk6yU5KPJ/lZkluSfCfJU6Zul+SAJD9odb6X5ClJJpJMDNR5dhsqsuOUbY9MUlPKNkzy6oF9/jTJO5LcaaDOjm1/f5vk9UmuSnJDks8l2W5IG5+f5NttyM/1Sb6a5M8G1t85yVuSXJrk1rb8p9kKhZI8MMkp7di/SvLfSf5iSp3jklyR5MFJvpbk5iQXJ/m7Ift7fJLzk/w6ybIkz2vbL2/rlwJfadXPaOeqWvngfg5IclGSXyY5L8mjZuP9SpLUBwYgkiSt374JHJzklUn+z3SVkmwPnAM8EHgZ8GTg28Ankzx5oN7jgU/QDan5K+BtwHuA+6xDGz8GvKbtdx/gX+iG63x8SN1XA7sAzwVeAjyybT/4Xt4OHNPavz/wDOAsYIe2fkPgdOB5re1PAD4E/HN7P+skyUOAb9CFT88H/hq4DvhSkodOqb4J3fv+GLAvcC7wgSSPGdjf/YBTgZXAAcA/tvc+OITp28Bh7fmL6c7LI1v5pL8AXtHe59OAJcB/Jdlsnd6wJEk94RAYSZLWb38HnAy8FXhrkuuAM4CPVNUXB+odCQTYo6qua2Wnt2Dk9cAprex1wA+AfSevIEnyA+B/gB+O2rh2VcTTgIOr6oRW/KUkK4CPJXlQVX1nYJPlVfX0ge23At6W5F5V9dMku9AFOO+qqpcPbHfqwPMDgUe193pWKzszCcARSd5SVdeO+l4GvA34CfDYqrq1tfN04Lt04cN+A3XvBrygqr7S6p0F7NXaOHlFx2uAm4C9qurmVu9rwKW0q3uq6qYk32/1L6qqs4e0axPgQVV1fdvH1XSByxPpQhhJkhY1rwCRJGk9VlU/Ah4M7AG8CfgO8BS6cOM1A1X3Bk4DbmxDUjYcuFLigUk2SbIEeDhw8uDwmfZle/laNnFv4Fbg5CnHnQxnHj2l/mlTXl/Ylju05ePp/n45ZjXHvAz4xpBj3gHYfe3eCiTZmO5c/z/gdwP7DvClIe/n5snwA6CqbgF+NPB+aO05bTL8aPWuorvKZBT/Mxl+NFPPnSRJi5pXgEiStJ6rqt/SDQE5CyDJvYAv0F3t8P72pfgewLPaY5i7AxvTBQTXDFk/rGxN3APYCPjlDMcdtGLK61vacnK+kMn6V6zmmPcGfrOGxxzFFnRDS/65PW4nyQYDAdL1Q6rcwh/eD8A2wLArUq5htDu+3ObcVdUt7aqXOw2vLknS4mIAIklSz7ShIh+im/9iV7p5Qq4Dvga8ZZrNfgqsogsNth6yfmu6qyom/botN5pSb2q4cF2r+xcM99Npyqfz87bclumH5FxHN3xk/2nWLx/xmINuAH4HvB84YViFqZPProGr6EKbqYb9HCRJ0loyAJEkaT2WZJs2XGKq+7bl5B1ivkA3aeb3qupXM+zvXOCpSY4cmANkN2BHbhuATD6/P92QjsnJR/ecsssvAK8CNq2qM9f0fc3gS3QBxKF0E34O8wW6iUlXVtUPZuGYv1dVv2zzczwQ+PZahB3DnA08McmdB+YA2Qb4c7pwZNLk1TAbz8IxJUladAxAJElav303yZfo5s64lG4izCfSTY56UlX9pNV7Ld2VIGcleR/dVRCb0wUYO1fVc1u9I+jmyvhMkg8CW9FNjDr1VrvnAj+mm6B0A7ov5y8A7jhYqaomkvwH3Rwg72xt+B1doPJE4FVtHpM1UlU/TvIu4OVJ7kY3eetvgUcAP6iq/6S7u8xz6CY+fQfwv3RXqvwR3d1v9hucb2Ma903y1CHlZwIvpxtudHqSD9OFFFsCDwGWVNXha/p+mjcCT237ezvdOfxnuiEwgwHLj+iu0nlum0T2FuCHVfWLEY8nSdKiZAAiSdL67Z/ogoTX0w2Z+C3dF+XDgXdPVqqqnyR5GN3dYN5MF2xcR3fnkuMH6n0pyUGt3qeAZcBL6W7LykC9VUn2pRsKchzd/BPvprvV7hFT2vgM4EV0t7b9J7ov7svpJmAdeW6Rqvr7JMvoApeD6eYXuYA2sWpV/SbJXu0cHArs1Or8mO5uMbeuwWH+uj2menhVnZfk4XTv82hgU+BndLek/be1eD/fT7IP3d1lTgKupBuqtDddUDRZ77okL6S7ouardHORPAaYGPWYkiQtRqmq+W6DJEla4JJMAFTV0vltyeKQ5K504dOpVXXIfLdHkqQ+8AoQSZKkeZbkvXS3vf0pcC+6K242p5vIVpIkzQIDEEmSpPl3J7phL1vTDdH5JvD4qrpgXlslSVKPOARGkiRJkiT13gbz3QBJkiRJkqS5ZgAiSZIkSZJ6zwBEkiRJkiT1ngGIJEmSJEnqPQMQSZIkSZLUewYgkiRJkiSp9/5/r+mr6uA4WnEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def decontracted(text):\n",
    "    # specific\n",
    "    text = re.sub(\"won't\", \"will not\", text)\n",
    "    text = re.sub(\"can't\", \"can not\", text)\n",
    "\n",
    "    # general\n",
    "    text = re.sub(\"n't\", \" not\", text)\n",
    "    text = re.sub(\"'re\", \" are\", text)\n",
    "    text = re.sub(\"'s\", \" is\", text)\n",
    "    text = re.sub(\"'d\", \" would\", text)\n",
    "    text = re.sub(\"'ll\", \" will\", text)\n",
    "    text = re.sub(\"'t\", \" not\", text)\n",
    "    text = re.sub(\"'ve\", \" have\", text)\n",
    "    text = re.sub(\"'m\", \" am\", text)\n",
    "\n",
    "    return text\n",
    "\n",
    "def cleanString(text):\n",
    "    # ? Remove HTML tags\n",
    "    text = BeautifulSoup(text).get_text()\n",
    "    \n",
    "    # ? Remove contractions\n",
    "    text = decontracted(text)\n",
    "\n",
    "    # ? Remove non alphabets characters\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    text = text.lower()\n",
    "\n",
    "    # ? split text into tokens to remove whitespaces\n",
    "    text = \" \".join(text.split())\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "# ? Checking for null values\n",
    "print(f\"Null values present in training dataset: {df[TEXT_FIELD].isnull().sum()}\")\n",
    "\n",
    "seq_len_initial = df[TEXT_FIELD].apply(lambda x: len(x.split()))\n",
    "\n",
    "# ? Cleaning the text\n",
    "df[TEXT_FIELD] = df[TEXT_FIELD].apply(cleanString)\n",
    "\n",
    "seq_len_final = df[TEXT_FIELD].apply(lambda x: len(x.split()))\n",
    "improvement = 100 * (seq_len_final.mean() - seq_len_initial.mean()) / seq_len_initial.mean()\n",
    "\n",
    "print(f\"Cleaning reduced text size by {improvement:.1f}%\")\n",
    "\n",
    "plt.figure(figsize=(15, 5), constrained_layout=True)\n",
    "plt.hist(seq_len_final, bins=50)\n",
    "plt.grid(True)\n",
    "plt.xlim(0, 1000)\n",
    "plt.title(\"Sequence Length Distribution\", fontsize=20)\n",
    "plt.xlabel(\"Sequence Length\", fontsize=16)\n",
    "plt.ylabel(\"Frequency\", fontsize=16)\n",
    "plt.savefig(RESULT_DIR / \"sequence_length_distribution.png\", facecolor='w')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 127656, Valid size: 31915\n"
     ]
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "dataset = TextDataset(df[TEXT_FIELD], df[LABEL_FIELDS].values, tokenizer, MAX_LEN)\n",
    "\n",
    "train_size = int(TRAIN_SPLIT * len(dataset))\n",
    "valid_size = len(dataset) - train_size\n",
    "train_dataset, valid_dataset = random_split(dataset, [train_size, valid_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Train size: {len(train_dataset)}, Valid size: {len(valid_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive weight: tensor([  9.4911,  99.0439,  17.9064, 326.3231,  19.2790, 109.8125])\n"
     ]
    }
   ],
   "source": [
    "y_train = train_dataset.dataset.labels[train_dataset.indices]\n",
    "pos_weight = (y_train==0.).sum(dim=0) / y_train.sum(dim=0)\n",
    "print(f\"Positive weight: {pos_weight}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBertClassifier(\n",
      "  (bert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (1): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (2): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (3): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (4): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (5): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=512, out_features=6, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "distilBert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\", num_labels=NUM_LABELS)\n",
    "\n",
    "# ? Freeze all the parameters\n",
    "for param in distilBert.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model = DistilBertClassifier(distilBert, NUM_LABELS).to(device)\n",
    "print(model)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight.to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "  [Batch 50\t/3990] Loss: 3.2857\n",
      "  [Batch 100\t/3990] Loss: 1.3849\n",
      "  [Batch 150\t/3990] Loss: 0.7804\n",
      "  [Batch 200\t/3990] Loss: 0.7296\n",
      "  [Batch 250\t/3990] Loss: 1.0126\n",
      "  [Batch 300\t/3990] Loss: 3.5447\n",
      "  [Batch 350\t/3990] Loss: 2.8762\n",
      "  [Batch 400\t/3990] Loss: 0.7378\n",
      "  [Batch 450\t/3990] Loss: 0.6616\n",
      "  [Batch 500\t/3990] Loss: 1.7465\n",
      "  [Batch 550\t/3990] Loss: 0.9239\n",
      "  [Batch 600\t/3990] Loss: 1.3230\n",
      "  [Batch 650\t/3990] Loss: 1.0710\n",
      "  [Batch 700\t/3990] Loss: 3.4412\n",
      "  [Batch 750\t/3990] Loss: 0.7549\n",
      "  [Batch 800\t/3990] Loss: 0.7210\n",
      "  [Batch 850\t/3990] Loss: 0.8419\n",
      "  [Batch 900\t/3990] Loss: 0.5034\n",
      "  [Batch 950\t/3990] Loss: 0.6335\n",
      "  [Batch 1000\t/3990] Loss: 0.6896\n",
      "  [Batch 1050\t/3990] Loss: 0.6937\n",
      "  [Batch 1100\t/3990] Loss: 0.4509\n",
      "  [Batch 1150\t/3990] Loss: 0.8828\n",
      "  [Batch 1200\t/3990] Loss: 0.4649\n",
      "  [Batch 1250\t/3990] Loss: 0.8438\n",
      "  [Batch 1300\t/3990] Loss: 0.5378\n",
      "  [Batch 1350\t/3990] Loss: 1.5059\n",
      "  [Batch 1400\t/3990] Loss: 0.6444\n",
      "  [Batch 1450\t/3990] Loss: 0.6789\n",
      "  [Batch 1500\t/3990] Loss: 0.4235\n",
      "  [Batch 1550\t/3990] Loss: 0.3829\n",
      "  [Batch 1600\t/3990] Loss: 0.6301\n",
      "  [Batch 1650\t/3990] Loss: 0.4200\n",
      "  [Batch 1700\t/3990] Loss: 1.5727\n",
      "  [Batch 1750\t/3990] Loss: 0.3463\n",
      "  [Batch 1800\t/3990] Loss: 0.4342\n",
      "  [Batch 1850\t/3990] Loss: 1.1641\n",
      "  [Batch 1900\t/3990] Loss: 0.4142\n",
      "  [Batch 1950\t/3990] Loss: 0.4392\n",
      "  [Batch 2000\t/3990] Loss: 0.5619\n",
      "  [Batch 2050\t/3990] Loss: 0.4452\n",
      "  [Batch 2100\t/3990] Loss: 0.5685\n",
      "  [Batch 2150\t/3990] Loss: 0.6178\n",
      "  [Batch 2200\t/3990] Loss: 1.1838\n",
      "  [Batch 2250\t/3990] Loss: 0.3671\n",
      "  [Batch 2300\t/3990] Loss: 0.7928\n",
      "  [Batch 2350\t/3990] Loss: 0.4297\n",
      "  [Batch 2400\t/3990] Loss: 1.2899\n",
      "  [Batch 2450\t/3990] Loss: 0.4510\n",
      "  [Batch 2500\t/3990] Loss: 1.0916\n",
      "  [Batch 2550\t/3990] Loss: 1.5733\n",
      "  [Batch 2600\t/3990] Loss: 0.5160\n",
      "  [Batch 2650\t/3990] Loss: 1.2714\n",
      "  [Batch 2700\t/3990] Loss: 0.5446\n",
      "  [Batch 2750\t/3990] Loss: 0.8863\n",
      "  [Batch 2800\t/3990] Loss: 3.9938\n",
      "  [Batch 2850\t/3990] Loss: 0.6365\n",
      "  [Batch 2900\t/3990] Loss: 0.3345\n",
      "  [Batch 2950\t/3990] Loss: 0.2768\n",
      "  [Batch 3000\t/3990] Loss: 0.2369\n",
      "  [Batch 3050\t/3990] Loss: 0.6182\n",
      "  [Batch 3100\t/3990] Loss: 0.3763\n",
      "  [Batch 3150\t/3990] Loss: 0.7531\n",
      "  [Batch 3200\t/3990] Loss: 0.2431\n",
      "  [Batch 3250\t/3990] Loss: 0.3064\n",
      "  [Batch 3300\t/3990] Loss: 1.3863\n",
      "  [Batch 3350\t/3990] Loss: 0.4332\n",
      "  [Batch 3400\t/3990] Loss: 0.6899\n",
      "  [Batch 3450\t/3990] Loss: 0.5336\n",
      "  [Batch 3500\t/3990] Loss: 0.1608\n",
      "  [Batch 3550\t/3990] Loss: 0.6138\n",
      "  [Batch 3600\t/3990] Loss: 0.4055\n",
      "  [Batch 3650\t/3990] Loss: 0.1733\n",
      "  [Batch 3700\t/3990] Loss: 3.2970\n",
      "  [Batch 3750\t/3990] Loss: 0.1686\n",
      "  [Batch 3800\t/3990] Loss: 0.2632\n",
      "  [Batch 3850\t/3990] Loss: 0.6949\n",
      "  [Batch 3900\t/3990] Loss: 0.3933\n",
      "  [Batch 3950\t/3990] Loss: 2.1614\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-ebb76cb3e7fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-66-ebb76cb3e7fc>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, dataloader, criterion, optimizer, device)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mavg_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mtotal_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal_preds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_preds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mavg_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_preds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "def train(model, dataloader, criterion, optimizer, device='cpu'):\n",
    "    print(\"Training...\")\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    total_preds = []\n",
    "\n",
    "    # ? iterate over batches\n",
    "    for idx, batch in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ids = batch['ids'].to(device)\n",
    "        mask = batch['mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(ids, mask)\n",
    "\n",
    "        # ? Compute the loss between actual and predicted values\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # ? Calculate the gradients via backpropagation\n",
    "        loss.backward()\n",
    "        # ? clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        # ? Update the model parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss = total_loss + loss.item()\n",
    "        total_preds.append(outputs.detach().cpu().numpy())\n",
    "\n",
    "        # ? progress update after every 50 batches.\n",
    "        if (idx + 1) % 50 == 0:\n",
    "            print(f\"  [Batch {idx+1}\\t/{len(dataloader)}] Loss: {loss.item():.4f}\")\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    total_preds = total_preds.reshape(-1, total_preds.shape[-1])\n",
    "\n",
    "    return avg_loss, total_preds\n",
    "\n",
    "\n",
    "train_loss, train_preds = train(model, train_dataloader, criterion, optimizer, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for evaluating the model\n",
    "def evaluate(dataloader, criterion, device):\n",
    "    print(\"\\nEvaluating...\")\n",
    "    model.eval()\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "\n",
    "    # empty list to save the model predictions\n",
    "    total_preds = []\n",
    "\n",
    "    for step, batch in enumerate(dataloader):\n",
    "        # Progress update every 50 batches.\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "\n",
    "            # Report progress.\n",
    "            print(\"  Batch {:>5,}  of  {:>5,}.\".format(step, len(dataloader)))\n",
    "\n",
    "        # push the batch to gpu\n",
    "        batch = [t.to(device) for t in batch]\n",
    "\n",
    "        sent_id, mask, labels = batch\n",
    "\n",
    "        # deactivate autograd\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # model predictions\n",
    "            preds = model(sent_id, mask)\n",
    "\n",
    "            # compute the validation loss between actual and predicted values\n",
    "            loss = criterion(preds, labels)\n",
    "\n",
    "            total_loss = total_loss + loss.item()\n",
    "\n",
    "            preds = preds.detach().cpu().numpy()\n",
    "\n",
    "            total_preds.append(preds)\n",
    "\n",
    "    # compute the validation loss of the epoch\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "    return avg_loss, total_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ? tokenize and encode sequences\n",
    "# tokens_train = tokenizer(X_train.tolist(), max_length=256, padding='max_length', truncation=True)\n",
    "# train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "# train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "# train_y = torch.tensor(y_train.tolist())\n",
    "# train_dataset = TensorDataset(train_seq, train_mask, train_y)\n",
    "# train_sampler = RandomSampler(train_dataset)\n",
    "# train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=BATCH_SIZE)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
